{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Working on GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA is available. Working on GPU')\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    print('CUDA is not available. Working on CPU')\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first five files from the list of train images: ['tiny-imagenet-200/train/n02233338/images/n02233338_162.JPEG', 'tiny-imagenet-200/train/n02233338/images/n02233338_99.JPEG', 'tiny-imagenet-200/train/n02233338/images/n02233338_495.JPEG', 'tiny-imagenet-200/train/n02233338/images/n02233338_76.JPEG', 'tiny-imagenet-200/train/n02233338/images/n02233338_24.JPEG']\n",
      "\n",
      "The first five labels from the list of train labels: ['n02233338', 'n02233338', 'n02233338', 'n02233338', 'n02233338']\n",
      "\n",
      "The first five files from the list of validation images: ['tiny-imagenet-200/val/images/val_7300.JPEG', 'tiny-imagenet-200/val/images/val_2747.JPEG', 'tiny-imagenet-200/val/images/val_405.JPEG', 'tiny-imagenet-200/val/images/val_9940.JPEG', 'tiny-imagenet-200/val/images/val_3863.JPEG']\n",
      "\n",
      "The first five labels from the list of validation labels: ['n02730930', 'n02190166', 'n02480495', 'n07720875', 'n02056570']\n",
      "\n",
      "The first five files from the list of test images: ['tiny-imagenet-200/test/images/test_0.JPEG', 'tiny-imagenet-200/test/images/test_1.JPEG', 'tiny-imagenet-200/test/images/test_10.JPEG', 'tiny-imagenet-200/test/images/test_100.JPEG', 'tiny-imagenet-200/test/images/test_1000.JPEG']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DIR_MAIN = 'tiny-imagenet-200/'\n",
    "DIR_TRAIN = DIR_MAIN + 'train/'\n",
    "DIR_VAL = DIR_MAIN + 'val/'\n",
    "DIR_TEST = DIR_MAIN + 'test/'\n",
    "\n",
    "# Number of labels - 200\n",
    "labels = os.listdir(DIR_TRAIN)\n",
    "\n",
    "# Initialize labels encoder\n",
    "encoder_labels = LabelEncoder()\n",
    "encoder_labels.fit(labels)\n",
    "\n",
    "# Create lists of files and labels for training (100'000 items)\n",
    "files_train = []\n",
    "labels_train = []\n",
    "for label in labels:\n",
    "    for filename in os.listdir(DIR_TRAIN + label + '/images/'):\n",
    "        files_train.append(DIR_TRAIN + label + '/images/' + filename)\n",
    "        labels_train.append(label)\n",
    "\n",
    "# Create lists of files and labels for validation (10'000 items)\n",
    "files_val = []\n",
    "labels_val = []\n",
    "for filename in os.listdir(DIR_VAL + 'images/'):\n",
    "    files_val.append(DIR_VAL + 'images/' + filename)\n",
    "\n",
    "val_df = pd.read_csv(DIR_VAL + 'val_annotations.txt', sep='\\t', names=[\"File\", \"Label\", \"X1\", \"Y1\", \"X2\", \"Y2\"], usecols=[\"File\", \"Label\"])\n",
    "for f in files_val:\n",
    "    l = val_df.loc[val_df['File'] == f[len(DIR_VAL + 'images/'):]]['Label'].values[0]\n",
    "    labels_val.append(l)\n",
    "\n",
    "# List of files for testing (10'000 items)\n",
    "files_test = []\n",
    "for filename in os.listdir(DIR_TEST + 'images/'):\n",
    "    files_test.append(DIR_TEST + 'images/' + filename)\n",
    "    files_test = sorted(files_test)\n",
    "print(\"The first five files from the list of train images:\", files_train[:5])\n",
    "print(\"\\nThe first five labels from the list of train labels:\", labels_train[:5])\n",
    "print(\"\\nThe first five files from the list of validation images:\", files_val[:5])\n",
    "print(\"\\nThe first five labels from the list of validation labels:\", labels_val[:5])\n",
    "print(\"\\nThe first five files from the list of test images:\", files_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, files, labels, encoder, transforms, mode):\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        self.encoder = encoder\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pic = Image.open(self.files[index]).convert('RGB')\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':\n",
    "            x = self.transforms(pic)\n",
    "            label = self.labels[index]\n",
    "            y = self.encoder.transform([label])[0]\n",
    "            return x, y\n",
    "        elif self.mode == 'test':\n",
    "            x = self.transforms(pic)\n",
    "            return x, self.files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.06, 0.08), ratio=(1, 3), value=0, inplace=True)\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImagesDataset(files=files_train,\n",
    "                              labels=labels_train,\n",
    "                              encoder=encoder_labels,\n",
    "                              transforms=transforms_train,\n",
    "                              mode='train')\n",
    "val_dataset = ImagesDataset(files=files_val,\n",
    "                            labels=labels_val,\n",
    "                            encoder=encoder_labels,\n",
    "                            transforms=transforms_val,\n",
    "                            mode='val')\n",
    "\n",
    "test_dataset = ImagesDataset(files=files_test,\n",
    "                             labels=None,\n",
    "                             encoder=None,\n",
    "                             transforms=transforms_val,\n",
    "                             mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, model_name, start_epoch, n_epochs, train_dataloader, val_dataloader):\n",
    "\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.33)\n",
    "\n",
    "    train_loss_array = []\n",
    "    train_acc_array = []\n",
    "    val_loss_array = []\n",
    "    val_acc_array = []\n",
    "    lowest_val_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    if start_epoch > 0:\n",
    "        resume_epoch = start_epoch - 1\n",
    "        resume(model, f\"epoch-{resume_epoch}.pth\")\n",
    "\n",
    "    for epoch in tqdm(range(start_epoch, n_epochs)):\n",
    "\n",
    "        print('Epoch: {} | Learning rate: {}'.format(epoch + 1, scheduler.get_lr()))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            epoch_loss = 0\n",
    "            epoch_correct_items = 0\n",
    "            epoch_items = 0\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                with torch.enable_grad(): \n",
    "                    for samples, targets in train_dataloader:\n",
    "                        samples = samples.to(DEVICE)\n",
    "                        targets = targets.to(DEVICE)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(samples)\n",
    "                        loss = loss_function(outputs, targets)\n",
    "                        preds = outputs.argmax(dim=1)\n",
    "                        correct_items = (preds == targets).float().sum()\n",
    "                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        epoch_loss += loss.item()\n",
    "                        epoch_correct_items += correct_items.item()\n",
    "                        epoch_items += len(targets)\n",
    "\n",
    "                train_loss_array.append(epoch_loss / epoch_items)\n",
    "                train_acc_array.append(epoch_correct_items / epoch_items)\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            elif phase == 'val':\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for samples, targets in val_dataloader:\n",
    "                        samples = samples.to(DEVICE)\n",
    "                        targets = targets.to(DEVICE)\n",
    "\n",
    "                        outputs = model(samples)\n",
    "                        loss = loss_function(outputs, targets)\n",
    "                        preds = outputs.argmax(dim=1)\n",
    "                        correct_items = (preds == targets).float().sum()\n",
    "\n",
    "                        epoch_loss += loss.item()\n",
    "                        epoch_correct_items += correct_items.item()\n",
    "                        epoch_items += len(targets)\n",
    "\n",
    "                val_loss_array.append(epoch_loss / epoch_items)\n",
    "                val_acc_array.append(epoch_correct_items / epoch_items)\n",
    "\n",
    "                if epoch_loss / epoch_items < lowest_val_loss:\n",
    "                    lowest_val_loss = epoch_loss / epoch_items\n",
    "                    torch.save(model.state_dict(), '{}_weights.pth'.format(model_name))\n",
    "                    checkpoint(model, f\"epoch-{epoch}.pth\")\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print(\"\\t| New lowest val loss for {}: {}\".format(model_name, lowest_val_loss))\n",
    "\n",
    "    return best_model, train_loss_array, train_acc_array, val_loss_array, val_acc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_vgg19_bn = models.vgg19_bn(pretrained=True)\n",
    "for param in model_vgg19_bn.parameters():\n",
    "    param.requires_grad = False\n",
    "model_vgg19_bn.classifier[6] = torch.nn.Linear(in_features=model_vgg19_bn.classifier[6].in_features, out_features=200)\n",
    "model_vgg19_bn = model_vgg19_bn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [05:25<10:50, 325.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t| New lowest val loss for VGG19_bn: 0.02846531791687012\n",
      "Epoch: 4 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      " 33%|███▎      | 1/3 [06:16<12:33, 376.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vgg19_bn_training_results \u001b[39m=\u001b[39m training(model\u001b[39m=\u001b[39;49mmodel_vgg19_bn,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                      model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mVGG19_bn\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                      start_epoch\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                                      n_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                                      train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                                      val_dataloader\u001b[39m=\u001b[39;49mval_dataloader)\n",
      "\u001b[1;32m/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m epoch_correct_items \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m correct_items\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.10.0.108/home/airi/yolo/Tensorflow-and-Pytorch-using-a-checkpoint/pytorch_checkpoint/pytorch_checkpoint.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m epoch_items \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(targets)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg19_bn_training_results = training(model=model_vgg19_bn,\n",
    "                                     model_name='VGG19_bn',\n",
    "                                     start_epoch=2,\n",
    "                                     n_epochs=5,\n",
    "                                     train_dataloader=train_dataloader,\n",
    "                                     val_dataloader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [05:24<05:24, 324.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t| New lowest val loss for VGG19_bn: 0.02817518684864044\n",
      "Epoch: 5 | Learning rate: [0.0003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airi/yolo/yolov8_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "100%|██████████| 2/2 [10:49<00:00, 324.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t| New lowest val loss for VGG19_bn: 0.028011473762989045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vgg19_bn_training_results = training(model=model_vgg19_bn,\n",
    "                                     model_name='VGG19_bn',\n",
    "                                     start_epoch=3,\n",
    "                                     n_epochs=5,\n",
    "                                     train_dataloader=train_dataloader,\n",
    "                                     val_dataloader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19_bn, train_loss_array, train_acc_array, val_loss_array, val_acc_array = vgg19_bn_training_results\n",
    "\n",
    "min_loss = min(val_loss_array)\n",
    "min_loss_epoch = val_loss_array.index(min_loss)\n",
    "min_loss_accuracy = val_acc_array[min_loss_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5635"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5576, 0.5635]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_env",
   "language": "python",
   "name": "yolov8_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
